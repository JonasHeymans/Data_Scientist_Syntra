{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86823938",
   "metadata": {},
   "source": [
    "# Pandas Student Notebook — Foundations Practice (6)  \n",
    "## Dataset: Kaggle “Netflix Movies and TV Shows”\n",
    "\n",
    "### Goal of this notebook\n",
    "This notebook focuses on categorical data, time-derived features, and rate-based reasoning.\n",
    "Students will practice cleaning messy text fields, deriving time features, and avoiding misleading counts.\n",
    "\n",
    "Key analytical habits:\n",
    "- Clean before grouping\n",
    "- Prefer rates and proportions over raw counts\n",
    "- Be explicit about time grain\n",
    "- Distinguish catalog size from activity or popularity\n",
    "\n",
    "File used:\n",
    "- `netflix_titles.csv`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b16fe1e",
   "metadata": {},
   "source": [
    "## 0. Setup + first inspection\n",
    "\n",
    "Load `netflix_titles.csv` into a DataFrame called `df`.\n",
    "\n",
    "Write as a comment:\n",
    "- What does one row represent in this dataset? (grain)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "67dd2386",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T20:52:23.631918Z",
     "start_time": "2026-01-06T20:52:23.231682Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import kagglehub\n",
    "import os\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"shivamb/netflix-shows\")\n",
    "\n",
    "df = pd.read_csv(os.path.join(path, 'netflix_titles.csv'))\n",
    "\n",
    "# Grain:\n",
    "# one row per Netflix title (movie or TV show)\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "ab81ba67",
   "metadata": {},
   "source": [
    "## 1. Missing values and empty strings\n",
    "\n",
    "1) Show missing values per column\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "94528fd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T20:52:23.665370Z",
     "start_time": "2026-01-06T20:52:23.633531Z"
    }
   },
   "source": "df.isna().sum().sort_values(ascending=False)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "director        2634\n",
       "country          831\n",
       "cast             825\n",
       "date_added        10\n",
       "rating             4\n",
       "duration           3\n",
       "show_id            0\n",
       "type               0\n",
       "title              0\n",
       "release_year       0\n",
       "listed_in          0\n",
       "description        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "71129a10",
   "metadata": {},
   "source": [
    "## 2. Date parsing and derived features\n",
    "\n",
    "1) Convert `date_added` to datetime.  \n",
    "2) Create:\n",
    "- `year_added`\n",
    "- `month_added`\n",
    "- `year_month_added`\n",
    "\n",
    "3) Count rows where `date_added` is missing.\n",
    "\n",
    "Write as a comment:\n",
    "- Why is `date_added` not the same as release year?\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "172119aa",
   "metadata": {},
   "source": [
    "df[\"date_added\"] = pd.to_datetime(df[\"date_added\"], errors=\"coerce\")\n",
    "\n",
    "df[\"year_added\"] = df[\"date_added\"].dt.year\n",
    "df[\"month_added\"] = df[\"date_added\"].dt.month\n",
    "df[\"year_month_added\"] = df[\"date_added\"].dt.to_period(\"M\").astype(str)\n",
    "\n",
    "missing_date_added = int(df[\"date_added\"].isna().sum())\n",
    "missing_date_added\n",
    "\n",
    "# Comment:\n",
    "# date_added is when Netflix added the title to its catalog; release_year is when it was produced/released."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "41d8f315",
   "metadata": {},
   "source": [
    "## 3. Cleaning categorical text columns\n",
    "\n",
    "Choose two columns among:\n",
    "- `type`\n",
    "- `rating`\n",
    "- `country`\n",
    "- `listed_in`\n",
    "\n",
    "Tasks:\n",
    "1) Standardize casing and strip whitespace.  \n",
    "2) Show `value_counts()` before and after cleaning.\n",
    "\n",
    "Write as a comment:\n",
    "- How can unclean categories silently distort groupby results?\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Quick sanity checks\n",
    "df[\"type\"].value_counts(dropna=False)\n",
    "df[\"rating\"].value_counts(dropna=False).head(15)\n"
   ],
   "id": "d718ec74ec817bd9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3f7365cf",
   "metadata": {},
   "source": [
    "# Clean 'type'\n",
    "df[\"type_clean\"] = df[\"type\"].str.strip()\n",
    "\n",
    "# Clean 'rating' (normalize casing + remove surrounding whitespace)\n",
    "df[\"rating_clean\"] = df[\"rating\"].str.strip().str.upper()\n",
    "\n",
    "# Clean 'country' (keep original, but make a cleaned string version for splitting later)\n",
    "df[\"country_clean_str\"] = df[\"country\"].str.strip()\n",
    "df[['type_clean','rating_clean', 'country_clean_str']].head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Quick sanity checks\n",
    "df[\"type_clean\"].value_counts(dropna=False)\n",
    "df[\"rating_clean\"].value_counts(dropna=False).head(15)\n",
    "\n",
    "\n",
    "# Unclean categories (extra spaces, inconsistent casing) create “fake” groups in groupby results,\n",
    "# silently splitting what should be the same category into multiple buckets.\n"
   ],
   "id": "bedba118e46f311c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "224c08a9",
   "metadata": {},
   "source": [
    "## 4. Movies vs TV Shows: proportions, not counts\n",
    "\n",
    "1) Compute raw counts of Movies vs TV Shows.  \n",
    "2) Compute proportions (percentages).  \n",
    "3) Show both in a small table.\n",
    "\n",
    "Write as a comment:\n",
    "- Why proportions are more informative than counts here?\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "b243dbe5",
   "metadata": {},
   "source": [
    "counts = df[\"type_clean\"].value_counts(dropna=False)\n",
    "props = df[\"type_clean\"].value_counts(normalize=True, dropna=False)\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"count\": counts,\n",
    "    \"share\": props\n",
    "})\n",
    "\n",
    "summary\n",
    "\n",
    "# Proportions are more informative because counts depend on total catalog size;\n",
    "# proportions let you compare composition even if catalog size changes.\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cd1c46f5",
   "metadata": {},
   "source": [
    "## 5. Time trends: catalog growth\n",
    "\n",
    "Compute number of titles added per year.\n",
    "\n",
    "Then compute:\n",
    "- cumulative number of titles over time\n",
    "\n",
    "Write as a comment:\n",
    "- Can this messure tell us something about viewing behavior?"
   ]
  },
  {
   "cell_type": "code",
   "id": "61dc3adc",
   "metadata": {},
   "source": [
    "titles_added_per_year = (\n",
    "    df.groupby(\"year_added\", dropna=False)[\"show_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"n_titles_added\")\n",
    "    .sort_values(\"year_added\")\n",
    ")\n",
    "\n",
    "titles_added_per_year\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Cumulative catalog additions over time (based on date_added)\n",
    "titles_added_per_year[\"cumulative_titles_added\"] = titles_added_per_year[\"n_titles_added\"].cumsum()\n",
    "titles_added_per_year\n",
    "\n",
    "# No, This measures catalog growth (titles added to Netflix), not viewing behavior/popularity,\n",
    "# because it uses date_added and not any engagement/watch metrics.\n"
   ],
   "id": "54413712c88ee6e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c8ebdde6",
   "metadata": {},
   "source": [
    "## 6. Ratings normalization\n",
    "\n",
    "For each rating:\n",
    "- compute number of titles\n",
    "- compute share of total titles\n",
    "\n",
    "Filter out ratings with fewer than 20 titles.\n",
    "\n",
    "Write as a comment:\n",
    "- Why filtering on minimum volume matters?\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "01e55609",
   "metadata": {},
   "source": [
    "rating_counts = (\n",
    "    df.groupby(\"rating_clean\")[\"show_id\"]\n",
    "    .nunique()\n",
    "    .rename(\"n_titles\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "total_titles = df[\"show_id\"].nunique()\n",
    "rating_counts[\"share_of_titles\"] = rating_counts[\"n_titles\"] / total_titles\n",
    "\n",
    "rating_counts = rating_counts.sort_values(\"n_titles\", ascending=False)\n",
    "rating_counts.head(15)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Filter out low-volume ratings (< 20)\n",
    "rating_counts_20 = rating_counts[rating_counts[\"n_titles\"] >= 20].copy()\n",
    "rating_counts_20\n",
    "\n",
    "\n",
    "# Minimum-volume filtering matters because small-n categories produce unstable shares and noisy comparisons.\n"
   ],
   "id": "3edfb8cba676cc7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1488b8ae",
   "metadata": {},
   "source": [
    "## 7. Data quality checks\n",
    "\n",
    "Create boolean `suspicious_title` if:\n",
    "- duration is missing\n",
    "- OR rating is missing\n",
    "- OR country is missing\n",
    "\n",
    "Show:\n",
    "- number of suspicious rows\n",
    "- sample rows\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "509f9b18",
   "metadata": {},
   "source": [
    "df[\"suspicious_title\"] = (\n",
    "    df[\"duration\"].isna()\n",
    "    | df[\"rating_clean\"].isna()\n",
    "    | df[\"country_clean_str\"].isna()\n",
    ")\n",
    "\n",
    "print(\"suspicious rows:\", int(df[\"suspicious_title\"].sum()))\n",
    "\n",
    "df.loc[df[\"suspicious_title\"], [\"show_id\", \"title\", \"duration\", \"rating\", \"country\"]].head(10)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4d20e12a",
   "metadata": {},
   "source": [
    "## 8. Capstone: analysis-ready table\n",
    "\n",
    "Create `analysis_df` with:\n",
    "- `type`\n",
    "- `year_added`\n",
    "- `rating`\n",
    "- primary country (first listed country)\n",
    "- number of genres\n",
    "- release year\n",
    "- suspicious_title (as int)\n",
    "\n",
    "Requirements:\n",
    "- No missing values in engineered columns\n",
    "- Show `analysis_df.head()` and `analysis_df.isna().sum()`\n",
    "\n",
    "Write as a comment:\n",
    "- Which column required the most care to construct, and why?\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "1ee74856",
   "metadata": {},
   "source": [
    "# Primary country = first listed country\n",
    "primary_country = (\n",
    "    df[\"country_clean_str\"]\n",
    "    .fillna(\"Unknown\")\n",
    "    .str.split(\",\")\n",
    "    .str[0]\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# Number of genres\n",
    "n_genres = (\n",
    "    df[\"listed_in\"]\n",
    "    .fillna(\"Unknown\")\n",
    "    .str.split(\",\")\n",
    "    .apply(len)\n",
    ")\n",
    "\n",
    "#Using vectorisation\n",
    "\n",
    "# n_genres = (\n",
    "#     df[\"listed_in\"]\n",
    "#     .fillna(\"Unknown\")\n",
    "#     .str.count(\",\")\n",
    "#     .add(1)\n",
    "# )\n",
    "\n",
    "\n",
    "analysis_df = pd.DataFrame({\n",
    "    \"type\": df[\"type_clean\"].fillna(\"Unknown\"),\n",
    "    \"year_added\": df[\"year_added\"].fillna(0).astype(int),   # no missing engineered cols\n",
    "    \"rating\": df[\"rating_clean\"].fillna(\"UNKNOWN\"),\n",
    "    \"primary_country\": primary_country.fillna(\"Unknown\"),\n",
    "    \"n_genres\": n_genres.fillna(0).astype(int),\n",
    "    \"release_year\": df[\"release_year\"].fillna(0).astype(int),\n",
    "    \"suspicious_title\": df[\"suspicious_title\"].fillna(False).astype(int),\n",
    "})\n",
    "\n",
    "analysis_df.head()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1b527c73f61d0c5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
